{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00000-2177f857-5779-403f-91bc-a18673125b8d",
    "deepnote_app_coordinates": {
     "h": 5,
     "w": 12,
     "x": 0,
     "y": null
    },
    "deepnote_cell_height": 83.83332824707031,
    "deepnote_cell_type": "code",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML, display\n",
    "display(HTML('<style>.container { width:100%; !important } </style>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00001-c29ba798-cd7a-4e45-8422-6ee928df7b27",
    "deepnote_app_coordinates": {
     "h": 5,
     "w": 12,
     "x": 0,
     "y": 6
    },
    "deepnote_cell_height": 81.83332824707031,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "# Minimax Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00001-dcc47b7a-49e6-4ca6-b283-cd23526a06c4",
    "deepnote_app_coordinates": {
     "h": 5,
     "w": 12,
     "x": 0,
     "y": 12
    },
    "deepnote_cell_height": 61.83332824707031,
    "deepnote_cell_type": "markdown",
    "owner_user_id": "1e489002-1d0e-4892-8dc4-49d215805343",
    "tags": []
   },
   "source": [
    "### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00001-200438c0-dc12-44fb-acf6-57aa4144be49",
    "deepnote_app_coordinates": {
     "h": 5,
     "w": 12,
     "x": 0,
     "y": 18
    },
    "deepnote_cell_height": 188.8333282470703,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 616,
    "execution_start": 1641662542265,
    "output_cleared": true,
    "source_hash": "abbad2f6",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import chess\n",
    "import random\n",
    "from typing import Union\n",
    "\n",
    "import import_ipynb\n",
    "import Util\n",
    "from Globals import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Minimax Algorithm is a simple algorithm for playing a game.\n",
    "This algorithm is based on the notion of the value of a State s. In the following, the formal definition of the Minimax-Algorithm, according to Prof. Dr. Karl Stroetmann in his lecture \"Artificial Intelligence\", is given. Therefore, the source for the following equations is the lecture of Prof. Dr. Karl Stroetmann (Stroetmann, K. 2022)\n",
    "\n",
    "$State$ is the set of all possible game-states.\n",
    "\n",
    "Firstly, let us define the function $finished$, which maps a State s to a value of the set $B$, with $B$ beeing defined as $B = \\{True, False\\} $. Therefore, $finished$ is defined as $$ finished : State \\rightarrow B$$\n",
    "With $finished$ defined, we can now define the set of $TerminalStates$, which is defined as follows:\n",
    "$$ TerminalStates := \\{s \\in States | finished(s) \\} $$\n",
    "\n",
    "Secondly, let us define the function utility, which maps a State s to a value. In Prof. Dr. Stroetmanns lecture, this is definded as follows:\n",
    "$$ utility : TerminalStates \\rightarrow \\{-1, 0 +1\\} $$\n",
    "Note, that the number of possible values in a chess game is much greater than defined in the lecture for this particular case. More in the following. \n",
    "\n",
    "Now let us define the function $value$. $Value$ is conceptionally an extension to the notion of $utility$ of a state. However, instead of mapping a value to a $TerminalState$, the function $value$ is defined for all states. Formally, we define a function \n",
    "$$maxValue : State \\rightarrow  \\{-1, 0 +1\\} $$\n",
    "This function takes a state s and returns a value that state has for the first player, who tries to maximize the value of the state. Here, we assume that all players play optimally.\n",
    "This function is defined by recursion.\n",
    "Due to the $maxValue$ function beeing an extension to the $utility$ function, the base case is as follows:\n",
    "$$ finished(s) \\rightarrow maxValue(s) = utility(s)$$\n",
    "If the game is not finished, we define\n",
    "$$ \\neg finished(s) \\rightarrow maxValue(s) = max(\\{minValue(n) | n  \\in nextStates(s,gPlayers[0])\\}). $$ \n",
    "\n",
    "The reason is that, if a game is not finished yet, the maximizing player gPlayers[0] has to evaluate all possible moves, in order to take the one move, which benefits him the most. Therefore, the player computes the set $nextStates(s, gPlayers[0])$ of all states that can be reached from the current state s. Next is the minimizing player gPlayers[1]. This player tries to minimize the possible value for the enemy player gPlayers[0]. Hence, in order to evaluate the state n, we call the function $minValue$ recursively as $minValue(n)$.\n",
    "The function $minValue$ is defined by the following recursive equations and has the same signature as $maxValue$:  \n",
    "\n",
    "$1.   finished(s) \\rightarrow minValue(s) = utility(s).$  \n",
    "$2.   \\neg finished(s) \\rightarrow minValue(s) = min(\\{maxValue(n) | n \\in nextStates(s, gPlayers[1])\\}).$\n",
    "\n",
    "In the following, we will speak of the $value$ function, which is used as a synonym for the function $maxValue$\n",
    "\n",
    "\n",
    "In the case of this implementation, the set of values is much greater. In this case, value maps the current board-state onto a number, calculated by taking into account the different piece-values and piece-square-tables. Therefore, value can map onto a range of -100 000 000 to 10 000 000, which is defined in Globals.py.  \n",
    "Instead of calling another function, we use the negated values of $ai_turn$ and $color$ to call the same function for the other player, hence calling the function recursively to calculate the best move.\n",
    "\n",
    "Optionally, the algorithm uses memoization, which is a type of caching. This works by mapping a board state, plus iteration details, to the corresponding score and move and storing it in a cache dictionary. If, during a later iteration, the same board state is reached on the same iteration, these values can be read from the cache."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00001-7a7c748f-d95c-4ec5-8bbb-309075e4fcb4",
    "deepnote_app_coordinates": {
     "h": 5,
     "w": 12,
     "x": 0,
     "y": 24
    },
    "deepnote_cell_height": 803.63330078125,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "#### chess.Board.get_best_move_minimax\n",
    "Finds the best move to make based on the minimax algorithm. This algorithm works as follows:\n",
    "- Iterate over all legal moves in the current position.\n",
    "- For each move, find the best possible score after making this move.\n",
    "    - This is done by calling the minimax function recursively: increasing the current iteration by 1 and switching turns.\n",
    "- Find the maximum (if it's the AI's turn) or the minimum (if it's the other player's/AI's turn) score of all legal moves, alongside the move that was able to reach this optimized state. This is the move that the algorithm recommends.\n",
    "\n",
    "Optionally, the algorithm uses memoization, which is a type of caching. This works by mapping a board state, plus iteration details, to the corresponding score and move and storing it in a cache dictionary. If, during a later iteration, the same board state is reached on the same iteration, these values can be read from the cache.\n",
    "\n",
    "__This function is implemented recursively.__\n",
    "\n",
    "###### <b><u>Arguments</u></b>\n",
    "``cache (dict):``  \n",
    "A cache dictionary if memoization is desired, or None if memoization should be disabled.  \n",
    "\n",
    "``use_heuristic (bool):``  \n",
    "Whether or not the heuristic for evaluating the chess board should be used. Chess problems don't need this heuristic.  \n",
    "\n",
    "``ai_turn (bool):``  \n",
    "Whether or not the current turn is of the AI that started the search. If this is the case, the score should be maximized. Otherwise, the score should be minimized.  \n",
    "\n",
    "``color (chess.Color):``  \n",
    "The color of the player whose turn it currently is.  \n",
    "\n",
    "``endgame_tablebase (Union[chess.gaviota.NativeTablebase, chess.gaviota.PythonTablebase]):``  \n",
    "The endgame tablebase attached to the game, which serves as a shortcut for ideal moves in the endgame.  \n",
    "\n",
    "``iteration (int):``  \n",
    "The depth of the search (amount of moves currently looking ahead).  \n",
    "\n",
    "``max_iterations (int):``  \n",
    "The maximum depth of the search.  \n",
    "\n",
    "``last_eval_score (int):``  \n",
    "The score provided by the previous evaluation in the search. \n",
    "\n",
    "###### <b><u>Returns <i>(int, chess.Move, bool)</i></u></b>\n",
    "- The board score after making the recommended best move.\n",
    "- The recommended best move to make.\n",
    "- Whether or not the endgame library was used to find the move.\n",
    "\n",
    "###### <b><u>Side effects</u></b>\n",
    "- If a cache dictionary is provided, new values may be added to this dictionary.\n",
    "- If the search is interrupted, the board may be in a different state than when the search started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00000-89802ca9-b1c9-46e5-ae87-9b8e860c2e24",
    "deepnote_app_coordinates": {
     "h": 5,
     "w": 12,
     "x": 0,
     "y": 30
    },
    "deepnote_cell_height": 1070.8333740234375,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 288,
    "execution_start": 1641396488427,
    "output_cleared": true,
    "source_hash": "53e9fa98",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_best_move_minimax(\n",
    "    self,\n",
    "    cache: dict,\n",
    "    use_heuristic: bool,\n",
    "    ai_turn: bool,\n",
    "    color: chess.Color,\n",
    "    endgame_tablebase: Union[chess.gaviota.NativeTablebase,\n",
    "            chess.gaviota.PythonTablebase],\n",
    "    iteration: int,\n",
    "    max_iterations: int,\n",
    "    last_eval_score: int\n",
    ") -> (int, chess.Move, bool):\n",
    "\n",
    "    if cache is not None and (iteration, self.get_state_string()) in cache:\n",
    "        return cache[(iteration, self.get_state_string())]\n",
    "\n",
    "    original_color = color if ai_turn else not color\n",
    "    result_score = self.get_search_result_if_finished(original_color, iteration,\n",
    "            max_iterations, last_eval_score)\n",
    "    if result_score is not None:\n",
    "        return result_score, None, False\n",
    "\n",
    "    # Check additional moves using the minimax algorithm\n",
    "    best_score = Globals.MAX_EVALUATION_SCORE * (-1 if ai_turn else 1)\n",
    "    best_move = None\n",
    "    best_move_used_endgame = False\n",
    "    for move in self.legal_moves:\n",
    "        eval_score, used_endgame_anywhere = self.evaluate_move(\n",
    "                use_heuristic, color, not ai_turn, last_eval_score,\n",
    "                iteration, move, endgame_tablebase)\n",
    "        self.push(move)\n",
    "        \n",
    "        if self.is_game_over():\n",
    "            score_after_move = eval_score\n",
    "        else:\n",
    "            score_after_move, _, used_endgame = self.get_best_move_minimax(\n",
    "                    cache, use_heuristic, not ai_turn, not color,\n",
    "                    endgame_tablebase, iteration + 1, max_iterations, eval_score)\n",
    "            used_endgame_anywhere = used_endgame_anywhere or used_endgame\n",
    "\n",
    "        self.pop()\n",
    "\n",
    "        if (ai_turn and score_after_move > best_score) \\\n",
    "                or (not ai_turn and score_after_move < best_score):\n",
    "            best_score = score_after_move\n",
    "            best_move = move\n",
    "            best_move_used_endgame = used_endgame_anywhere\n",
    "\n",
    "    if cache is not None:\n",
    "        cache_key = (iteration, self.get_state_string())\n",
    "        cache[cache_key] = best_score, best_move, best_move_used_endgame\n",
    "\n",
    "    return best_score, best_move, best_move_used_endgame\n",
    "\n",
    "chess.Board.get_best_move_minimax = get_best_move_minimax\n",
    "del get_best_move_minimax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00004-e2bc0d01-d112-4903-958d-9cbc4466983d",
    "deepnote_app_coordinates": {
     "h": 5,
     "w": 12,
     "x": 0,
     "y": 36
    },
    "deepnote_cell_height": 447.433349609375,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "#### make_move_minimax\n",
    "Finds the best possible move according to the minimax algorithm and pushes it onto the move stack.\n",
    "\n",
    "###### <b><u>Arguments</u></b>\n",
    "``board (chess.Board):``  \n",
    "The board to push the move to.  \n",
    "\n",
    "``color (chess.Color):``  \n",
    "The color of the player that makes the move.  \n",
    "\n",
    "``search_depth (int):``  \n",
    "The iteration depth of the minimax search.  \n",
    "\n",
    "``endgame_tablebase (Union[chess.gaviota.NativeTablebase, chess.gaviota.PythonTablebase]):``  \n",
    "The endgame tablebase attached to the game, which serves as a shortcut for ideal moves in the endgame.  \n",
    "\n",
    "``use_heuristic (bool):``  \n",
    "Whether or not the heuristic for evaluating the chess board should be used. Chess problems don't need this heuristic.\n",
    "\n",
    "###### <b><u>Returns <i>(int, chess.Move, bool)</i></u></b>\n",
    "- The evaluated score of the best possible move.\n",
    "- The best possible move that was found.\n",
    "- Whether or not the endgame library was used to find the move.\n",
    "\n",
    "###### <b><u>Side effects</u></b>\n",
    "- The best possible move is pushed to the move stack of the board."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00003-917b88be-6d67-4d5c-aeac-7051f3c7e5fc",
    "deepnote_app_coordinates": {
     "h": 5,
     "w": 12,
     "x": 0,
     "y": 42
    },
    "deepnote_cell_height": 458.83331298828125,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1,
    "execution_start": 1637933609103,
    "source_hash": "f8eaada3",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_move_minimax(\n",
    "    board: chess.Board,\n",
    "    color: chess.Color,\n",
    "    search_depth: int,\n",
    "    endgame_tablebase: Union[chess.gaviota.NativeTablebase,\n",
    "            chess.gaviota.PythonTablebase],\n",
    "    use_heuristic: bool\n",
    ") -> (int, chess.Move, bool):\n",
    "\n",
    "    score, move, used_endgame = board.get_best_move_minimax(\n",
    "        cache=None, \n",
    "        use_heuristic=use_heuristic,\n",
    "        ai_turn=True, \n",
    "        color=color, \n",
    "        endgame_tablebase=endgame_tablebase,\n",
    "        iteration=0, \n",
    "        max_iterations=search_depth, \n",
    "        last_eval_score=0 # The starting board score doesn't matter,\n",
    "                          # it's evaluated by score difference\n",
    "    )\n",
    "    board.push(move)\n",
    "    return score, move, used_endgame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00008-f20586a7-8b85-4b84-9634-38b7a3128476",
    "deepnote_app_coordinates": {
     "h": 5,
     "w": 12,
     "x": 0,
     "y": 48
    },
    "deepnote_cell_height": 447.433349609375,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "#### make_move_minimax_memoization\n",
    "Finds the best possible move according to the minimax algorithm and pushes it onto the move stack. The algorithm is optimized using memoization (a type of caching).\n",
    "\n",
    "###### <b><u>Arguments</u></b>\n",
    "``board (chess.Board):``  \n",
    "The board to push the move to.  \n",
    "\n",
    "``color (chess.Color):``  \n",
    "The color of the player that makes the move.  \n",
    "\n",
    "``search_depth (int):``  \n",
    "The iteration depth of the minimax search.  \n",
    "\n",
    "``endgame_tablebase (Union[chess.gaviota.NativeTablebase, chess.gaviota.PythonTablebase]):``  \n",
    "The endgame tablebase attached to the game, which serves as a shortcut for ideal moves in the endgame.  \n",
    "\n",
    "``use_heuristic (bool):``  \n",
    "Whether or not the heuristic for evaluating the chess board should be used. Chess problems don't need this heuristic.\n",
    "\n",
    "###### <b><u>Returns <i>(int, chess.Move, bool)</i></u></b>\n",
    "- The evaluated score of the best possible move.\n",
    "- The best possible move that was found.\n",
    "- Whether or not the endgame library was used to find the move.\n",
    "\n",
    "###### <b><u>Side effects</u></b>\n",
    "- The best possible move is pushed to the move stack of the board."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00008-e316cbb7-808a-476b-85b6-dbe3f6805f0f",
    "deepnote_app_coordinates": {
     "h": 5,
     "w": 12,
     "x": 0,
     "y": 54
    },
    "deepnote_cell_height": 443.83331298828125,
    "deepnote_cell_type": "code",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_move_minimax_memoization(\n",
    "    board: chess.Board,\n",
    "    color: chess.Color,\n",
    "    search_depth: int,\n",
    "    endgame_tablebase: Union[chess.gaviota.NativeTablebase,\n",
    "            chess.gaviota.PythonTablebase],\n",
    "    use_heuristic: bool,\n",
    ") -> (int, chess.Move, bool):\n",
    "\n",
    "    score, move, used_endgame = board.get_best_move_minimax(\n",
    "        cache={}, \n",
    "        use_heuristic=use_heuristic,\n",
    "        ai_turn=True, \n",
    "        color=color, \n",
    "        endgame_tablebase=endgame_tablebase,\n",
    "        iteration=0, \n",
    "        max_iterations=search_depth, \n",
    "        last_eval_score=0 # The starting board score doesn't matter,\n",
    "                          # it's evaluated by score difference\n",
    "    )\n",
    "    board.push(move)\n",
    "    return score, move, used_endgame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=d6ce9acd-52c5-4422-904d-8424da19408b' target=\"_blank\">\n",
    "<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\n",
    "Created in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>"
   ]
  }
 ],
 "metadata": {
  "deepnote": {
   "is_reactive": false
  },
  "deepnote_app_layout": "article",
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "4b2bc438-db4f-4a2d-a41c-2db325d56891",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
