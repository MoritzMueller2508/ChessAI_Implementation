{
 "cells": [
  {
   "cell_type": "markdown",
   "source": "# Alpha-beta pruning algorithm",
   "metadata": {
    "tags": [],
    "cell_id": "00001-c358cce6-2aff-4654-b7eb-eb6f0810073f",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "### Dependencies",
   "metadata": {
    "tags": [],
    "cell_id": "00001-3f544fa2-3e1d-4cf9-85f4-553b75404d38",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00001-bddf5d66-c8ba-4ae2-be82-34d272432057",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "dadbc17a",
    "execution_start": 1637933565648,
    "execution_millis": 9259,
    "deepnote_cell_type": "code"
   },
   "source": "import chess\nimport random\nimport signal\nimport time\n\nimport import_ipynb\nimport Util",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": "importing Jupyter notebook from Game.ipynb\nRequirement already satisfied: python-chess in /usr/local/lib/python3.7/site-packages (1.999)\nRequirement already satisfied: chess<2,>=1 in /usr/local/lib/python3.7/site-packages (from python-chess) (1.7.0)\n\u001b[33mWARNING: You are using pip version 20.1.1; however, version 21.3.1 is available.\nYou should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\u001b[0m\nNote: you may need to restart the kernel to use updated packages.\nimporting Jupyter notebook from Util.ipynb\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "### get_best_move_alphabeta\nFinds the best move to make based on the alpha-beta pruning algorithm. This algorithm works as follows:\n- Iterate over all legal moves in the current position.\n- For each move, find the best possible score after making this move.\n    - This is done by calling the alpha-beta pruning function recursively: increasing the current iteration by 1 and switching turns.\n    - If a move yields a worse score than the previously examined move in the hierarchy, it is unlikely that this will ever be the optimal move. Therefore, such moves are not evaluated further.\n- Find the maximum (if it's the AI's turn) or the minimum (if it's the player's turn) score of all legal moves, alongside the move that was able to reach this optimized state. This is the move that the algorithm recommends.\n\nOptionally, the algorithm uses memoization, which is a type of caching. This works by mapping a board state, plus iteration details, to the corresponding score and move and storing it in a cache dictionary. If, during a later iteration, the same board state is reached on the same iteration, these values can be read from the cache.\n\n##### Member of class\n    chess.Board\n\n##### Arguments\n    use_cache: bool\n        Argument to decide if memoization should be used or not.\n    alpha: int\n        The \"alpha\" value in the current iteration. On the first iteration, this value should be strongly negative.\n    beta: int\n        The \"beta\" value in the current iteration. On the first iteration, this value should be strongly positive.\n    ai_turn : bool\n        Is the current turn of the AI to take?\n    iteration: int\n        The depth of the search (amount of moves currently looking ahead).\n    max_iterations: int\n        The maximum depth of the search.\n\n##### Returns\n    tuple(best_score, best_move)\n\n    best_score: int\n        The board score after making the recommended best move.\n    best_move: chess.Move\n        The recommended best move to make.\n\n##### Side effects\n    - If use_cache is true, the cache is constantly updated with different board states in combination with the best score and move.\n    - If the search is interrupted, the board may be in a different state than when the search started.",
   "metadata": {
    "tags": [],
    "cell_id": "00003-32528de8-188f-4576-b697-033fd4194f00",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00000-b7c8cf8f-e01f-4e59-9631-2964ed372358",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "8e69fb13",
    "execution_start": 1637933574910,
    "execution_millis": 39,
    "deepnote_cell_type": "code"
   },
   "source": "alpha_beta_cache = {}\n\ndef get_best_move_alphabeta(self, use_cache: bool, alpha: int, beta: int, ai_turn: bool, color: chess.Color,\n                            iteration: int, max_iterations: int, last_eval_score: int) -> (int, chess.Move):\n                            \n    if use_cache and (iteration, max_iterations, self.get_state_string()) in alpha_beta_cache:\n        return alpha_beta_cache[(iteration, max_iterations, self.get_state_string())]\n\n    result = self.get_search_result_if_finished(iteration, max_iterations, last_eval_score)\n    if result is not None: return result\n\n    # If the game has not finished, check additional moves using the alpha-beta pruning algorithm\n    best_score, best_move = 10000000 * (-1 if ai_turn else 1), None\n    for move in self.legal_moves:\n        eval_score = self.evaluate_move(color, not ai_turn, last_eval_score, move)\n        self.push(move)\n        score_after_move, _ = self.get_best_move_alphabeta(use_cache, alpha, beta, not ai_turn, not color, iteration + 1,\n                                                           max_iterations, eval_score)\n        if (ai_turn and score_after_move > best_score) or (not ai_turn and score_after_move < best_score):\n            best_score = score_after_move\n            best_move = move\n        self.pop()\n\n        if ai_turn:\n            if best_score >= beta:\n                return best_score, move\n            if best_score > alpha:\n                alpha = best_score\n        else:\n            if best_score <= alpha:\n                return best_score, move\n            if best_score < beta:\n                beta = best_score\n\n    if use_cache: alpha_beta_cache[(iteration, max_iterations, self.get_state_string())] = best_score, best_move\n    return best_score, best_move\n\nchess.Board.get_best_move_alphabeta = get_best_move_alphabeta",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "---\n<br>\n\n## OutOfTimeError class\nA custom exception class that should be raised if a time limit is exceeded.\n<br><br>\n\n### Class variables\n    N/A\n<br>\n\n### \\_\\_init\\_\\_\n    The constructor for the OutOfTimeError class. Gets called whenever a new OutOfTimeError instance is created (most commonly, when an OutOfTimeError is raised).\n<br>\n\n##### Arguments\n    message : str (optional)\n        A message explaining the raised exception.\n\n##### Returns\n    N/A\n\n##### Side effects\n    N/A",
   "metadata": {
    "tags": [],
    "cell_id": "00005-24a79507-3811-4d6c-80ed-7b0c54135dc8",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00002-b8592edb-69a6-4510-a59d-e4fe0059fa0b",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "a7c61259",
    "execution_start": 1637933574963,
    "execution_millis": 52,
    "deepnote_cell_type": "code"
   },
   "source": "class OutOfTimeError(Exception):\n    def __init__(self, message='Out of time'):\n        self.message = message\n        super().__init__(self.message)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### time_limit_signal_handler\nHandles the signal that is created when a time limit is exceeded by raising an OutOfTimeError.\n\n##### Arguments\n    signum: int\n        The signal number corresponding to the signal that triggered this handler.\n    frame: signal.frame\n        The current stack frame as the signal is triggered.\n\n##### Returns\n    N/A\n\n##### Side effects\n    - An OutOfTimeError is raised.",
   "metadata": {
    "tags": [],
    "cell_id": "00007-b8e7cb16-d48a-40b0-8ee6-71215eeed42f",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00006-a8e4aa5a-0f95-4ed8-b2bc-2f86a94aad55",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "8dbdb769",
    "execution_start": 1637933575015,
    "execution_millis": 49,
    "deepnote_cell_type": "code"
   },
   "source": "def time_limit_signal_handler(signum, frame):\n    raise OutOfTimeError()",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### get_best_move_alphabeta_iterative_deepening\nPerforms an alpha-beta search using the previously described algorithm. However, this function uses iterative deepening, which means that it iterates over a range between 1 and a given maximum depth limit, and on each iteration, it finds the best move using an alpha-beta search with the current maximum depth. Essentially, it moves through the search tree horizontally, rather than hierarchically.\n\nThe advantage of this method is that the search can be interrupted at any time, yielding the best move at the previously evaluated depth. Enabling memoization is strongly recommended to reach acceptable performance.\n\nThe search stops if either the maximum depth is reached, or if the time limit is exceeded, whichever occurs first.\n\n##### Member of class\n    chess.Board\n\n##### Arguments\n    use_cache: bool\n        Argument to decide if memoization should be used or not.\n    max_iterations: int\n        The maximum depth of the search.\n    time_limit: int\n        The maximum duration of the search, in seconds.\n\n##### Returns\n    tuple(best_score, best_move)\n\n    best_score: int\n        The board score after making the recommended best move.\n    best_move: chess.Move\n        The recommended best move to make.\n\n##### Side effects\n    - If use_cache is true, the cache is constantly updated with different board states in combination with the best score and move.\n    - If the search is interrupted, the board may be in a different state than when the search started.",
   "metadata": {
    "tags": [],
    "cell_id": "00006-a40ad7ae-42a4-475b-ad7e-22300c5a86f6",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00001-a8035622-3ae2-441a-befd-4650b58f3ee7",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "5e193761",
    "execution_start": 1637933575095,
    "execution_millis": 2,
    "deepnote_cell_type": "code"
   },
   "source": "def get_best_move_alphabeta_iterative_deepening(self, use_cache: bool, color: chess.Color, max_iterations: int, time_limit: int) -> chess.Move:\n    signal.signal(signal.SIGALRM, time_limit_signal_handler)\n    signal.alarm(time_limit)\n\n    best_move = None\n    board_state = self.fen() # Save state, because the board may be in a different state if the search is interrupted\n\n    try:\n        for current_max_iterations in range(1, max_iterations + 1):\n            _, best_move = self.get_best_move_alphabeta(\n                use_cache=use_cache,\n                alpha=-100000000,\n                beta=100000000,\n                ai_turn=True,\n                color=color,\n                iteration=0,\n                max_iterations=current_max_iterations,\n                last_eval_score=0 # The starting board score doesn't matter, it's evaluated by score difference\n            )\n    except OutOfTimeError:\n        # The exception will trigger after a fixed amount of time\n        self.set_fen(board_state) # Reset the board state because the search was interrupted, leaving the board in a different state\n\n    return best_move\n\nchess.Board.get_best_move_alphabeta_iterative_deepening = get_best_move_alphabeta_iterative_deepening",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "---\n<br>\n\n## make_move_alphabeta\n\nThis function gets the best possible move according to the alpha-beta pruning algorithm and pushes it onto the move stack.\n\n#### Arguments\n    board: chess.Board\n        The board to push the move to.\n#### Returns\n    N/A\n#### Side effects\n    - The best possible move is pushed to the move stack of the board.",
   "metadata": {
    "tags": [],
    "cell_id": "00011-23576796-2219-48b5-9b85-338d5304a3fa",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00004-f54aaa33-8247-43b3-9098-2890db438a8d",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "7d50cb7b",
    "execution_start": 1637933575122,
    "execution_millis": 1,
    "deepnote_cell_type": "code"
   },
   "source": "def make_move_alphabeta(board: chess.Board, color: chess.Color) -> None:\n    _, move = board.get_best_move_alphabeta(\n        use_cache=True, \n        alpha=-100000000, \n        beta=100000000, \n        ai_turn=True, \n        color=color,\n        iteration=0, \n        max_iterations=5,\n        last_eval_score=0 # The starting board score doesn't matter, it's evaluated by score difference\n    )\n    \n    board.push(move)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "---\n<br>\n\n## make_move_alphabeta_iterative_deepening\n\nThis function gets the best possible move according to the alpha-beta pruning algorithm, with iterative deepening, and pushes it onto the move stack.\n\n#### Arguments\n    board: chess.Board\n        The board to push the move to.\n#### Returns\n    N/A\n#### Side effects\n    - The best possible move is pushed to the move stack of the board.",
   "metadata": {
    "tags": [],
    "cell_id": "00013-e1549338-881c-43d1-88ac-cd7c5a2f7347",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00012-f15b4d9f-cd5c-4ac7-8266-9a154387df08",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "604c11cd",
    "execution_start": 1637933575123,
    "execution_millis": 55,
    "deepnote_cell_type": "code"
   },
   "source": "def make_move_alphabeta_iterative_deepening(board: chess.Board, color: chess.Color) -> None:\n    move = board.get_best_move_alphabeta_iterative_deepening(use_cache=True, color=color, max_iterations=10, time_limit=30)\n    board.push(move)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00005-a6d66c25-da31-4abf-ac54-51b7c634351d",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "ef0eb914",
    "execution_start": 1637933575179,
    "execution_millis": 1384445517,
    "deepnote_output_heights": [
     null,
     542.75,
     443.6000061035156
    ],
    "deepnote_cell_type": "code"
   },
   "source": "##game = Game.Gam2e(make_move_alphabeta_iterative_deepening)\n#game.play()",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00006-3e94a31b-e27d-46b1-b1e2-5882b9fb7ea9",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "b623e53d",
    "execution_start": 1637933575180,
    "deepnote_cell_type": "code"
   },
   "source": "",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=d6ce9acd-52c5-4422-904d-8424da19408b' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>",
   "metadata": {
    "tags": [],
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown"
   }
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "orig_nbformat": 2,
  "deepnote": {
   "is_reactive": false
  },
  "deepnote_notebook_id": "a3aa8d62-1517-4618-8cd7-29b3aa7b5c6c",
  "deepnote_execution_queue": []
 }
}